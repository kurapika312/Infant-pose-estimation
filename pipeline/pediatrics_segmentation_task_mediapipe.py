# -*- coding: utf-8 -*-
"""Pediatrics-Segmentation-Task.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Y04sTpG9NrkaQCgdfbo_aJzLFEjcxlCf

# Detectron2 Beginner's Tutorial

<img src="https://dl.fbaipublicfiles.com/detectron2/Detectron2-Logo-Horz.png" width="500">

Welcome to detectron2! This is the official colab tutorial of detectron2. Here, we will go through some basics usage of detectron2, including the following:
* Run inference on images or videos, with an existing detectron2 model
* Train a detectron2 model on a new dataset

You can make a copy of this tutorial by "File -> Open in playground mode" and make changes there. __DO NOT__ request access to this tutorial.

# Install detectron2
"""
import pathlib
import torch
import tqdm
TORCH_VERSION = ".".join(torch.__version__.split(".")[:2])
CUDA_VERSION = torch.__version__.split("+")[-1]
print("torch: ", TORCH_VERSION, "; cuda: ", CUDA_VERSION)


# import some common libraries
import numpy as np
import cv2
import mediapipe as mp
from mediapipe.tasks import python
from mediapipe.tasks.python import vision


"""# Run a pre-trained detectron2 model

!python -m pip install pyyaml==5.1
import sys, os, distutils.core
# Note: This is a faster way to install detectron2 in Colab, but it does not include all functionalities.
# See https://detectron2.readthedocs.io/tutorials/install.html for full installation instructions
!git clone 'https://github.com/facebookresearch/detectron2'
dist = distutils.core.run_setup("./detectron2/setup.py")
!python -m pip install {' '.join([f"'{x}'" for x in dist.install_requires])}
sys.path.insert(0, os.path.abspath('./detectron2'))

# Properly install detectron2. (Please do not install twice in both ways)
# !python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'

We first download an image from the COCO dataset:

Then, we create a detectron2 config and a detectron2 `DefaultPredictor` to run inference on this image.
"""
images_dir = pathlib.Path('assets/Ashok-RGB2D/RGB')
images_save_dir = pathlib.Path('assets/Ashok-RGB2D/SEGMENTATION')
images_glob = images_dir.glob('*.png')

# Create the options that will be used for ImageSegmenter
base_options = python.BaseOptions(model_asset_path='./models/mediapipe/segmentation/deeplab_v3.tflite')
options = vision.ImageSegmenterOptions(base_options=base_options,
                                       output_category_mask=True)
BG_COLOR = (0, 0, 0) # gray
MASK_COLOR = (255, 255, 255) # white
images_save_dir.mkdir(exist_ok=True, parents=True)

for im_path in tqdm.tqdm(images_glob):
  im_segmentation_name = f'{im_path.stem.split("-")[0]}-SEGMENTATION'
  im_segmentation_path = f'{images_save_dir.joinpath(im_segmentation_name)}.png'

  # # Create the image segmenter
  with vision.ImageSegmenter.create_from_options(options) as segmenter:
    # Create the MediaPipe image file that will be segmented
    image = mp.Image.create_from_file(f'{im_path}')
    # Retrieve the masks for the segmented image
    segmentation_result = segmenter.segment(image)
    category_mask = segmentation_result.category_mask
    
    # Generate solid color images for showing the output segmentation mask.
    image_data = image.numpy_view()
    fg_image = np.zeros(image_data.shape, dtype=np.uint8)
    fg_image[:,:,:-1] = MASK_COLOR
    bg_image = np.zeros(image_data.shape, dtype=np.uint8)
    bg_image[:,:,:-1] = BG_COLOR

    condition = np.stack((category_mask.numpy_view(),) * 3, axis=-1) > 0.2
    output_image = np.where(condition, fg_image[:,:,:-1], bg_image[:,:,:-1])
    cv2.imwrite(im_segmentation_path, output_image)